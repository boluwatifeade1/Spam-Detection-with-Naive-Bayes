{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spam Detection with Naive Bayes .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "B36crJwlqzFj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Spam Detection with Naive Bayes\n",
        "Spam detection is one of the major applications of Machine Learning in the interwebs today. Pretty much all of the major email service providers have spam detection systems built in and automatically classify such mail as 'Junk Mail' or ' Spam'.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0LrvCU26rCJ_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####Data imports , loading and preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "6igVJRIZTWCW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "5ef276a5-7068-4d74-de09-56cb90135abe"
      },
      "cell_type": "code",
      "source": [
        "!unzip smsspamcollection.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  smsspamcollection.zip\n",
            "  inflating: SMSSpamCollection       \n",
            "  inflating: readme                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gCnDAlchNoNS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data_path='SMSSpamCollection'\n",
        "# Dataset from - https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
        "data = pd.read_table(data_path,\n",
        "                   sep='\\t', \n",
        "                   header=None, \n",
        "                   names=['label', 'sms_message'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C34InM_JUCEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "85353bc6-c795-4137-a574-0a10db624c44"
      },
      "cell_type": "code",
      "source": [
        "#viewing the first five rows of the datasets\n",
        "data.head()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                        sms_message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "metadata": {
        "id": "y1XTfkYYV8xv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "641821de-7eae-4b11-eb7e-bb30cd7d5bee"
      },
      "cell_type": "code",
      "source": [
        "data['label'] = data.label.map({'ham':0, 'spam':1}) # creates a binary map for spam and not spam\n",
        "print(data.shape)\n",
        "data.head() # returns shape of data (rows, columns)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5572, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        sms_message\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "metadata": {
        "id": "LOJEH2P4rPcd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "What we have here in our data set is a large collection of text data (5,572 rows of data). Most ML algorithms rely on numerical data to be fed into them as input, and email/sms messages are usually text heavy.\n",
        "\n",
        "Here we'd like to introduce the Bag of Words(BoW) concept which is a term used to specify the problems that have a 'bag of words' or a collection of text data that needs to be worked with. The basic idea of BoW is to take a piece of text and count the frequency of the words in that text. It is important to note that the BoW concept treats each word individually and the order in which the words occur does not matter.\n",
        "\n",
        "Using a process which we will go through now, we can covert a collection of documents to a matrix, with each document being a row and each word(token) being the column, and the corresponding (row,column) values being the frequency of occurrance of each word or token in that document."
      ]
    },
    {
      "metadata": {
        "id": "d9MXrXa9rlZ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To handle this, we will be using sklearns count vectorizer method which does the following:\n",
        "\n",
        "* It tokenizes the string(separates the string into individual words) and gives an integer ID to each token.\n",
        "* It counts the occurrance of each of those tokens.\n"
      ]
    },
    {
      "metadata": {
        "id": "D3PckDz3Vtvr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#imports\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vector=CountVectorizer() # Instantiate the CountVectorizer method"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ot64rNVSkUVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "98e5ff00-4394-46df-e8a1-fcdd3b0ee175"
      },
      "cell_type": "code",
      "source": [
        "print(count_vector)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
            "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "        tokenizer=None, vocabulary=None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zx_ufxEYrsST",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "####mini implementation on how sklearn count-vectorizers works on a small set of text features called documents\n"
      ]
    },
    {
      "metadata": {
        "id": "m32wLHDIkW1o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "documents = ['Hello, how are you!',\n",
        "                'Win money, win from home.',\n",
        "                'Call me now.',\n",
        "                'Hello, Call hello you tomorrow?']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y4LAyAKQkdLA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "outputId": "efd319b1-30d8-4625-9ae9-d40a43260eed"
      },
      "cell_type": "code",
      "source": [
        "count_vector.fit(documents)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "        tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "jmOCUjz4kinq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "4730d12b-1ebe-495a-b6dd-23fde8083a4a"
      },
      "cell_type": "code",
      "source": [
        "count_vector.get_feature_names() # returns unique words in the documents datasets"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['are',\n",
              " 'call',\n",
              " 'from',\n",
              " 'hello',\n",
              " 'home',\n",
              " 'how',\n",
              " 'me',\n",
              " 'money',\n",
              " 'now',\n",
              " 'tomorrow',\n",
              " 'win',\n",
              " 'you']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "metadata": {
        "id": "786Q5W3xklut",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "7f4759c5-27cd-4d14-addc-a756c3f1e13a"
      },
      "cell_type": "code",
      "source": [
        "doc_array = count_vector.transform(documents).toarray()\n",
        "doc_array"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "metadata": {
        "id": "z7IgtZj2scL8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above creates a binary map for word occurnence in each row of documenr for the uniques words from feature_names where 1 means present and is beings converted to a dataframe below for easy visualization"
      ]
    },
    {
      "metadata": {
        "id": "DrqnQcJlkxs0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "b3250e26-6ab7-4bd7-e3e0-4102b2367626"
      },
      "cell_type": "code",
      "source": [
        "frequency_matrix = pd.DataFrame(doc_array, \n",
        "                                columns = count_vector.get_feature_names())\n",
        "frequency_matrix"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>are</th>\n",
              "      <th>call</th>\n",
              "      <th>from</th>\n",
              "      <th>hello</th>\n",
              "      <th>home</th>\n",
              "      <th>how</th>\n",
              "      <th>me</th>\n",
              "      <th>money</th>\n",
              "      <th>now</th>\n",
              "      <th>tomorrow</th>\n",
              "      <th>win</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   are  call  from  hello  home  how  me  money  now  tomorrow  win  you\n",
              "0    1     0     0      1     0    1   0      0    0         0    0    1\n",
              "1    0     0     1      0     1    0   0      1    0         0    2    0\n",
              "2    0     1     0      0     0    0   1      0    1         0    0    0\n",
              "3    0     1     0      2     0    0   0      0    0         1    0    1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "XOvHa9m3s_Ql",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us split our main data-sets into train and test"
      ]
    },
    {
      "metadata": {
        "id": "qLTkv5-BmA94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f3c7a8e5-fe7d-4e4d-df5e-cad73837699e"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['sms_message'], \n",
        "                                                    data['label'], \n",
        "                                                    random_state=1)\n",
        "print('Number of rows in the total set: {}'.format(data.shape[0]))\n",
        "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
        "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in the total set: 5572\n",
            "Number of rows in the training set: 4179\n",
            "Number of rows in the test set: 1393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Oo5YQdIXymvd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1195
        },
        "outputId": "ec5c9465-070b-4f2d-abe6-cd7b5fba10fa"
      },
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "710     4mths half price Orange line rental & latest c...\n",
              "3740                           Did you stitch his trouser\n",
              "2711    Hope you enjoyed your new content. text stop t...\n",
              "3155    Not heard from U4 a while. Call 4 rude chat pr...\n",
              "3748    Ü neva tell me how i noe... I'm not at home in...\n",
              "2389    wiskey Brandy Rum Gin Beer Vodka Scotch Shampa...\n",
              "3464    i am seeking a lady in the street and a freak ...\n",
              "772     Lol! U drunkard! Just doing my hair at d momen...\n",
              "3667    I'm turning off my phone. My moms telling ever...\n",
              "4955    U coming back 4 dinner rite? Dad ask me so i r...\n",
              "854     AH POOR BABY!HOPE URFEELING BETTERSN LUV! PROB...\n",
              "4079                  Gam gone after outstanding innings.\n",
              "2837                         Nice.nice.how is it working?\n",
              "1392                  Haha just kidding, papa needs drugs\n",
              "5533    Hey chief, can you give me a bell when you get...\n",
              "874     Ugh its been a long day. I'm exhausted. Just w...\n",
              "4408    Awesome, plan to get here any time after like ...\n",
              "3990    Ok lor. Anyway i thk we cant get tickets now c...\n",
              "1921                        Dont know you bring some food\n",
              "749     Is there a reason we've not spoken this year? ...\n",
              "2947                        make that 3! 4 fucks sake?! x\n",
              "2378    YES! The only place in town to meet exciting a...\n",
              "83                   You will be in the place of that man\n",
              "4668                           I send the print  outs da.\n",
              "128                                Are you there in room.\n",
              "4521    What to think no one saying clearly. Ok leave ...\n",
              "5090                             St andre, virgil's cream\n",
              "885     Yoyyooo u know how to change permissions for a...\n",
              "134     Sunshine Quiz Wkly Q! Win a top Sony DVD playe...\n",
              "3060    Dear all, as we know  &lt;#&gt; th is the  &lt...\n",
              "                              ...                        \n",
              "1031    Can not use foreign stamps in this country. Go...\n",
              "1110                      S s..first time..dhoni rocks...\n",
              "1888    Urgent! Please call 09061743811 from landline....\n",
              "3550    I got like $ &lt;#&gt; , I can get some more l...\n",
              "1527    Wow ... I love you sooo much, you know ? I can...\n",
              "753                           Dont gimme that lip caveboy\n",
              "3049             Die... Now i have e toot fringe again...\n",
              "2628    I know I'm lacking on most of this particular ...\n",
              "562                      Thanx 4 e brownie it's v nice...\n",
              "4764                           Prepare to be pleasured :)\n",
              "3562    Text BANNEDUK to 89555 to see! cost 150p texto...\n",
              "252     Wen ur lovable bcums angry wid u, dnt take it ...\n",
              "2516    Bognor it is! Should be splendid at this time ...\n",
              "2962    I'm doing da intro covers energy trends n pros...\n",
              "4453    I've told you everything will stop. Just dont ...\n",
              "5374    Do u konw waht is rael FRIENDSHIP Im gving yuo...\n",
              "5396             As in i want custom officer discount oh.\n",
              "1202                                 I know she called me\n",
              "3462    K.. I yan jiu liao... Sat we can go 4 bugis vi...\n",
              "2797    Tell your friends what you plan to do on Valen...\n",
              "4225    Double eviction this week - Spiral and Michael...\n",
              "144            I know you are. Can you pls open the back?\n",
              "5056    Am on a train back from northampton so i'm afr...\n",
              "2895                     K...k...yesterday i was in cbe .\n",
              "2763    ARR birthday today:) i wish him to get more os...\n",
              "905     We're all getting worried over here, derek and...\n",
              "5192    Oh oh... Den muz change plan liao... Go back h...\n",
              "3980    CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...\n",
              "235     Text & meet someone sexy today. U can find a d...\n",
              "5157                              K k:) sms chat with me.\n",
              "Name: sms_message, Length: 4179, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "metadata": {
        "id": "c--mbv4ZqkoT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#lets apply countVectorizers to our main dataset\n",
        "count_vector = CountVectorizer() # Instantiate the CountVectorizer method\n",
        "\n",
        "training_data = count_vector.fit_transform(X_train) # Fit to the training data and then return the matrix\n",
        "\n",
        "# Transform testing data and return the matrix. Note we are not fitting the testing data into the CountVectorizer()\n",
        "testing_data = count_vector.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "85YUCji2tvyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b595bb81-795c-416d-b42a-3fa5dae19bf0"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(training_data, y_train)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "6RY4bfnStyar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predictions = naive_bayes.predict(testing_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Qkd5VIKGwa3R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "a7c11c17-31ac-4b97-eb55-bf50d11a5285"
      },
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "metadata": {
        "id": "27i2tkTOw5TS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Evaluating model\n",
        "Accuracy measures how often the classifier makes the correct prediction. It’s the ratio of the number of correct predictions to the total number of predictions (the number of test data points).\n",
        "\n",
        "Precision tells us what proportion of messages we classified as spam, actually were spam. It is a ratio of true positives(words classified as spam, and which are actually spam) to all positives(all words classified as spam, irrespective of whether that was the correct classification), in other words it is the ratio of\n",
        "\n",
        "[True Positives/(True Positives + False Positives)]\n",
        "\n",
        "Recall(sensitivity) tells us what proportion of messages that actually were spam were classified by us as spam. It is a ratio of true positives(words classified as spam, and which are actually spam) to all the words that were actually spam, in other words it is the ratio of\n",
        "\n",
        "[True Positives/(True Positives + False Negatives)]\n",
        "\n",
        "For classification problems that are skewed in their classification distributions like in our case, for example if we had a 100 text messages and only 2 were spam and the rest 98 weren't, accuracy by itself is not a very good metric. We could classify 90 messages as not spam(including the 2 that were spam but we classify them as not spam, hence they would be false negatives) and 10 as spam(all 10 false positives) and still get a reasonably good accuracy score. For such cases, precision and recall come in very handy. These two metrics can be combined to get the F1 score, which is weighted average of the precision and recall scores. This score can range from 0 to 1, with 1 being the best possible F1 score.\n",
        "\n",
        "We will be using all 4 metrics to make sure our model does well. For all 4 metrics whose values can range from 0 to 1, having a score as close to 1 as possible is a good indicator of how well our model is doing.\n"
      ]
    },
    {
      "metadata": {
        "id": "Mp3QUbJCwcsu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "outputId": "c3373b4c-2fc5-4a12-cb38-6516365972d4"
      },
      "cell_type": "code",
      "source": [
        "# computing the various metrics of the model\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
        "print('Precision score: ', format(precision_score(y_test, predictions)))\n",
        "print('Recall score: ', format(recall_score(y_test, predictions)))\n",
        "print('F1 score: ', format(f1_score(y_test, predictions)))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.9885139985642498\n",
            "Precision score:  0.9720670391061452\n",
            "Recall score:  0.9405405405405406\n",
            "F1 score:  0.9560439560439562\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}